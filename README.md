# awesome-chinese-nlp
A curated list of resources for NLP (Natural Language Processing) for Chinese
中文自然语言处理相关资料

## Contents 列表

 ### 1. [Chinese NLP Toolkits 中文NLP工具](https://github.com/crownpku/awesome-chinese-nlp#chinese-nlp-toolkits-中文nlp工具) 
 
  1.1 [Toolkits 综合NLP工具包](https://github.com/crownpku/awesome-chinese-nlp#toolkits-综合nlp工具包) 
  1.2 [Popular NLP Toolkits for English/Multi-Language 常用的英文或支持多语言的NLP工具包](https://github.com/crownpku/awesome-chinese-nlp#popular-nlp-toolkits-for-englishmulti-language-常用的英文或支持多语言的nlp工具包)
  1.3 [Chinese Word Segment 中文分词](https://github.com/crownpku/awesome-chinese-nlp#chinese-word-segment-中文分词)
  1.4 [Information Extraction 信息提取](https://github.com/crownpku/awesome-chinese-nlp#information-extraction-信息提取)
  1.5 [QA & Chatbot 问答和聊天机器人](https://github.com/crownpku/awesome-chinese-nlp#qa--chatbot-问答和聊天机器人)
  
  
 ### 2. [Corpus 中文语料](https://github.com/crownpku/awesome-chinese-nlp#corpus-中文语料)  
 
 
 ### 3. [Organizations 相关中文NLP组织和会议](https://github.com/crownpku/awesome-chinese-nlp#organizations-相关中文nlp组织和会议)
 
 
 ### 4. [Learning Materials 学习资料](https://github.com/crownpku/awesome-chinese-nlp#learning-materials-学习资料)
 
 


## Chinese NLP Toolkits 中文NLP工具


### Toolkits 综合NLP工具包

- THULAC 中文词法分析工具包 by 清华 (C++/Java/Python) [[link](http://thulac.thunlp.org/)]

- NLPIR by 中科院 (Java) [[github](https://github.com/NLPIR-team/NLPIR)]

- LTP 语言技术平台 by 哈工大 (C++) [[github](https://github.com/HIT-SCIR/ltp)]

- FudanNLP by 复旦 (Java) [[github](https://github.com/FudanNLP/fnlp)]

- CoreNLP by Stanford (Java) [[github](https://github.com/stanfordnlp/CoreNLP)]

- BosonNLP by Boson (商业API服务) [[link](http://bosonnlp.com/)]

- HanNLP (Java) [[github](https://github.com/hankcs/HanLP)]

- SnowNLP (Python) [[github](https://github.com/isnowfy/snownlp)] Python library for processing Chinese text

- YaYaNLP (Python) [[github](https://github.com/Tony-Wang/YaYaNLP)] 纯python编写的中文自然语言处理包，取名于“牙牙学语”

- DeepNLP (Python) [[github](https://github.com/rockingdingo/deepnlp)] Deep Learning NLP Pipeline implemented on Tensorflow with pretrained Chinese models.

- chinese_nlp (C++ & Python) [[github](https://github.com/taozhijiang/chinese_nlp)] Chinese Natural Language Processing tools and examples


### Popular NLP Toolkits for English/Multi-Language 常用的英文或支持多语言的NLP工具包

- CoreNLP by Stanford (Java) [[github](https://github.com/stanfordnlp/CoreNLP)]

- NLTK (Python) [[link](http://www.nltk.org/)]

- spaCy (Python) [[link](https://spacy.io/)]

- OpenNLP (Java) [[link](https://opennlp.apache.org/)]

- gensim (Python) [[github](https://github.com/RaRe-Technologies/gensim)] Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. 


### Chinese Word Segment 中文分词

- Jieba 结巴中文分词 (Python) [[github](https://github.com/fxsjy/jieba)] 做最好的 Python 中文分词组件

- kcws 深度学习中文分词 (Python) [[github](https://github.com/koth/kcws)] BiLSTM+CRF与IDCNN+CRF

- Genius 中文分词 (Python) [[github](https://github.com/duanhongyi/genius)] Genius是一个开源的python中文分词组件，采用 CRF(Conditional Random Field)条件随机场算法。

- loso 中文分词 (Python) [[github](https://github.com/fangpenlin/loso)] 


### Information Extraction 信息提取

- MITIE (C++) [[github](https://github.com/mit-nlp/MITIE)] library and tools for information extraction

- Duckling (Haskell) [[github](https://github.com/facebookincubator/duckling)] Language, engine, and tooling for expressing, testing, and evaluating composable language rules on input strings.

- IEPY (Python) [[github](https://github.com/machinalis/iepy)] IEPY is an open source tool for Information Extraction focused on Relation Extraction.

- Snorkel: A training data creation and management system focused on information extraction [[github](https://github.com/HazyResearch/snorkel)]

- Neural Relation Extraction implemented with LSTM in TensorFlow [[github](https://github.com/thunlp/TensorFlow-NRE)]

- A neural network model for Chinese named entity recognition [[github](https://github.com/zjy-ucas/ChineseNER)]


### QA & Chatbot 问答和聊天机器人 

- Rasa NLU (Python) [[github](https://github.com/RasaHQ/rasa_nlu)] turn natural language into structured data 

- Chatterbot (Python) [[github](https://github.com/gunthercox/ChatterBot)] ChatterBot is a machine learning, conversational dialog engine for creating chat bots.

- Chatbot (Python) [[github](https://github.com/zake7749/Chatbot)] 基於向量匹配的情境式聊天機器人

- Tipask (PHP) [[github](https://github.com/sdfsky/tipask)] 一款开放源码的PHP问答系统，基于Laravel框架开发，容易扩展，具有强大的负载能力和稳定性。

- QuestionAnsweringSystem (Java) [[github](https://github.com/ysc/QuestionAnsweringSystem)] 一个Java实现的人机问答系统，能够自动分析问题并给出候选答案。

- 使用TensorFlow实现的Sequence to Sequence的聊天机器人模型 (Python) [[github](https://github.com/qhduan/Seq2Seq_Chatbot_QA)] 


## Corpus 中文语料

- 开放知识图谱OpenKG.cn [[link](http://openkg.cn)]

- CLDC中文语言资源联盟 [[link](http://www.chineseldc.org/)]

- 用于训练中英文对话系统的语料库 Datasets for Training Chatbot System [[github](https://github.com/candlewill/Dialog_Corpus)]

- 中文 Wikipedia Dump [[link](https://dumps.wikimedia.org/zhwiki/)]

- 98年人民日报词性标注库@百度盘 [[link](https://pan.baidu.com/s/1gd6mslt)]

- 百度百科100gb语料@百度盘) [[link](http://pan.baidu.com/s/1i3wvfil)] 密码neqs 出处应该是梁斌penny大神

- 搜狗20061127新闻语料(包含分类)@百度盘 [[link](https://pan.baidu.com/s/1bnhXX6Z)]

- UDChinese (for training spaCy POS) [[github](https://github.com/UniversalDependencies/UD_Chinese)]

- 八卦版問答中文語料 [[github](https://github.com/zake7749/Gossiping-Chinese-Corpus)]

- 中文word2vec模型 [[github](https://github.com/to-shimo/chinese-word2vec)]

- 中文突发事件语料库（Chinese Emergency Corpus）[[github](https://github.com/shijiebei2009/CEC-Corpus)]

- dgk_lost_conv 中文对白语料 chinese conversation corpus [[github](https://github.com/rustch3n/dgk_lost_conv)]

- 漢語拆字字典 [[github](https://github.com/kfcd/chaizi)]

- 中国股市公告信息爬取 [[github](https://github.com/startprogress/China_stock_announcement)] 通过python脚本从巨潮网络的服务器获取中国股市（sz,sh）的公告(上市公司和监管机构)

- tushare财经数据接口 [[website](http://tushare.org/)] TuShare是一个免费、开源的python财经数据接口包。

- 保险行业语料库 [[github](https://github.com/Samurais/insuranceqa-corpus-zh)] [[52nlp介绍Blog](http://www.52nlp.cn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BF%9D%E9%99%A9%E8%A1%8C%E4%B8%9A%E9%97%AE%E7%AD%94%E5%BC%80%E6%94%BE%E6%95%B0%E6%8D%AE%E9%9B%86)] OpenData in insurance area for Machine Learning Tasks

- 最全中华古诗词数据库 [[github](https://github.com/chinese-poetry/chinese-poetry)] 唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。


## Organizations 相关中文NLP组织和会议

- 中国中文信息学会 [[website](http://www.cipsc.org.cn/)]

- NLP Conference Calender [[website](http://cs.rochester.edu/~omidb/nlpcalendar/)] Main conferences, journals, workshops and shared tasks in NLP community.


## Learning Materials 学习资料

- 中文Deep Learning Book [[github](https://github.com/exacity/deeplearningbook-chinese)]

- Stanford CS224n Natural Language Processing with Deep Learning 2017 [[link](http://web.stanford.edu/class/cs224n/syllabus.html)]

- Oxford CS DeepNLP 2017 [[github](https://github.com/oxford-cs-deepnlp-2017)]

- Speech and Language Processing by Dan Jurafsky and James H. Martin [[link](https://web.stanford.edu/~jurafsky/slp3/)]

- 52nlp 我爱自然语言处理 [[blog](http://www.52nlp.cn/)]

- hankcs 码农场 [[blog](http://www.hankcs.com/)]

- 文本处理实践课资料 [[github](https://github.com/Roshanson/TextInfoExp)] 文本处理实践课资料，包含文本特征提取（TF-IDF），文本分类，文本聚类，word2vec训练词向量及同义词词林中文词语相似度计算、文档自动摘要，信息抽取，情感分析与观点挖掘等实验。


